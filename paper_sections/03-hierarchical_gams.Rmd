---
output:
  pdf_document: default
  html_document: default
---

# What do we mean by hierarchical smooths?

Ecological data is often hierarchically structured, with observations occurring in groups (which may in turn may be grouped at higher levels). The smoothers we went over in section II allowed us to model global nonlinear relationships between our **x** and **y** variables. However, in many cases we want to fit a different functional relationship for each level of a grouping variable. In this section, we will cover the different ways to model inter-group variability in smooth curves, and how to fit the different models in mgcv.

When modelling hierarchical smooths in mgcv, there are three broad choices to make:

1. Should each the functional relationship between x and y for each group have its own smooth, or will a global smooth term suffice? 

2. Do all of the group-specific curves have similar smoothness to one another, or should each group have its own smoothness penalty?

3. Will the different smooth functions for each group have a similar shape to one another? That is, there a shared global average curve?



The combination of these three questions results in 5 possible models (figure *models*) beyond the null model of no functional relation between **x** and **y**:

1. A single common smooth function for all observations.

2. A single common smooth function plus group-level functions that are all similarly smooth to one another.

3. A single common smooth plus group-level functions that vary in smoothness from one another.

4. Group-specific smooth functions without an average trend, but with all functions being similarly smooth.

5. Group-specific functions that differ in smoothness. 


![](../figures/alternate_models.png)

We will discuss the trade-offs between different models and  guidelines about when each of these models is appropriate in section IV. The remainder of this section will focus on how to model each of these 5 models using `mgcv`. 

# Coding hierarchical GAMs in R

**EJP: Going with simulated data for the examples rather than real as it's a bit less messy, and lets us show true functions to compare with simulated.**

Each of these models can be coded straightforwardly in `mgcv`. To help illustrate this throughout the section when describing how to set these models up, we will refer to outcome variables as **y**,  continuous predictor variables as **x** (or **x1** and  **x2**, in the case multiple predictors), and **fac** to designate the discrete grouping factor whose variation we are interested in understanding.

We will also use two example datasets to demonstrate how to code these models, one real and one simulated (see the appendix for code to generate these examples):

A. The CO2 dataset, available in R in the default *datasets* package (loaded by default). This data is from an experimental study by CITE of $CO_2$ uptake in grasses under varying concentrations of $CO_2$, measuring how concentration-uptake functions varied between plants from two locations (Mississippi and Quebec) and two temperature treatments (chilled and warm). A total of 12 plants were measured, and uptake measured at 7 concentration levels for each plant. Here we will focus on how to use these techniques to estimate inter-plant variation in functional responses. 

B. A hypothetical study of bird movement along a migration corridor. This dataset consists of records of numbers of observed locations of 100 tagged individuals each from six species of bird, at ten locations along a latitudinal gradient, with one observation taken every four weeks. Not every bird was observed at each time point, so counts vary randomly between location and week. The data set (bird_move) consists of the variables `count`, `latitude`, `week` and `species`. This example will allow us to demonstrate how to fit these models with interactions and with non-normal (count) data. 


## A single global smooth term (model 1)

 This is the typical GAM setup, with a single smooth term for each variable. Specifying the model is similar to specifying a `glm` in R. One-dimensional or isotropic multidimensional smooth terms are specified with a function named `s()`. The first arguments (given without names) are the terms to be smoothed over. The type of smooth to be used for the term is specified by writing `bs=<basis name>`, and the number of basis functions is specified by `k=<number of functions>`. The `s()` function will also take additional arguments, depending on the type of smooth. Both `bs` and `k` have default values; `bs` defaults to a thin-plate spline (`bs="tp"`) and `k` defaults to a value determined by the type of smoother (`k=10` by default for `bs="tp"`). See the documentation in `mgcv` for more details on specifying smooth terms, with `?mgcv::s` and `?mgcv::smooth.terms`. For a given `gam` model, you can have an arbitrary number of smooth terms, connected by putting `+` between each `s()` function. This is equivalent to including linear terms without interactions in a standard `glm` model. Models like this look like `y~s(x)` for a simple smooth relationship between **x** and **y** or `y~s(x)+s(fac, bs="re")`, to model both a global smooth relationship between **x** and **y** and between-group variation in intercepts (modelled with a random effect smoother).

For our CO2 data set, we will use two basic smooth terms: a thin plate spline to model the average functional relationship between $CO_2$ concentration and uptake, and a simple random effect smoother for species to model species-specific intercepts [^f1] [^f2]. 

[^f1]:Note that we're actually modelling ln(uptake); this can be a useful approach when dealing with estimating multiple functional relationships as it means that functions that differ from each other by a multiplicative constant (so $f_1(x) = \alpha\cdot f_2(x)$ will differ by an additive constant when log-transformed (which can be estimated by simple random effects): $ln(f_1(x)) = ln(\alpha)+ ln(f_2(x))$. We have also ln-transformed concentration. Since the concentration-uptake relationship changes rapidly at low concentration values and slowly at higher values, estimating the relationship without log-transforming it can lead to a small estimated penalty value, and an overly wiggly function at higher concentration values.)

[^f2]: Note also that we have also specified `method="REML"`. This tells `mgcv` to use Restricted Maximum Likelihood [CITE] to estimate model coefficients and penalty terms. We strongly recommend using either `method="REML"` or `method="ML"` (marginal likelihood) when fitting models, as the default `method="GCV.Cp"` is not as consistent at estimating smoothing penalties as the likelihood-based methods and tends to substantially under-smooth terms [CITE]. 


```{r co2_mod1, echo=TRUE,  fig.width=6, fig.height=3,message=F, warning=F, cache=F}
library(mgcv)
library(ggplot2)

#The default CO2 plant variable is ordered, but mgcv treats ordered factors 
#differently than unordered. This recodes it to an unordered factor
CO2$Plant_uo = factor(CO2$Plant, levels = levels(CO2$Plant), ordered = F)

CO2_mod1 = gam(log(uptake) ~ s(log(conc),k=7,m=2, bs="tp")+s(Plant_uo, k =12,  bs="re"), 
               data= CO2,method="REML")

plot(CO2_mod1,page = 1, seWithMean = T)


```

This shows how to fit the model, and shows the default plot for the model for `mgcv`. The plot has two panels: the first showing the estimated global functional relationship, and the second showing the estimated distribution of random effects for the plant-specific intercepts.


Here is how you could plot this to illustrate inter-plant variation in the functional response with estimated functional variability, plotting untransformed uptake and concentration to make the figure easier to comprehend. You can see the effect log-transforming concentration has on model fits; even though plants Mc1 -- Mc3 show a much flatter response in untransformed space, the same functional response fits relatively well after accounting for the random effect (a multiplicative difference between functional responses).


```{r co2_mod1_ggplot, echo=TRUE,  fig.width=6, fig.height=3,message=F, warning=F, cache=T}

CO2_mod1_pred = predict(CO2_mod1,se.fit = T)
CO2$mod1 = CO2_mod1_pred$fit
CO2$mod1_se = CO2_mod1_pred$se.fit

ggplot(data=CO2, aes(x=conc, y= uptake, group=Plant_uo))+
  facet_wrap(~Plant_uo)+
  geom_point()+
  geom_line(aes(y=exp(mod1)))+
  geom_ribbon(aes(ymin=exp(mod1-2*mod1_se), ymax=exp(mod1+2*mod1_se)),alpha=0.5)
```



Global smooth models with interactions are also straightforward to model. For isotropic smooths such as thin-plate splines, extra terms can simply be added to the `s()` function (`y~s(x1,x2)`). For non-isotropic smooths, we use the tensor product (`te()`) function. It is specified similarly to the `s()` function, but requires additional information to specify the types of basis and number of basis functions used for each marginal term. `bs` can be specified as a single value, in which case that basis is used for all marginal terms in the model. `k` can also be given as a single value, and works similar to `bs`. For example, `y~te(x1,x2, k=c(10,5), bs=c("tp","cs"))`, would specify a non-isotropic smooth of **x1** and **x2**, with the marginal basis for **x1** being a thin-plate spline with 10 basis functions, and **x2** having  a cubic regression spline with a penalty on the null space. As with `s()`, the user can also give `te()` more options depending on the basis types used. For more information, consult `?mgcv::te`.

For our bird example, we will use one smooth term, a tensor product of latitude and week. We will use using a 10 basis function thin plate spline for the marginal latitude effects, and a 10 basis function cyclic cubic spline for the marginal week effect to account for the cyclic nature of weekly effects (we expect week 1 and week 52 to have very similar values). We will also assume the date (counts of individuals at each location in each week) follow a Poisson distribution. For simplicity of code we will exclude a species-specific random effect like the one we had in the $CO_2$ uptake example[^f3].

[^f3]:If we included it, it could be interpreted as modelling variation in average observability between species. However, as we cheated and know what the data generating process looks like, we do not need to worry about adding it here. 

Note that the total number of basis functions used for a given smooth is the product of the marginal `k` values, so in this example the global smooth would have 99 parameters (10*10, minus one to account for the presence of the global intercept). It will also have two smoothing parameters estimated; one for each marginal basis (week and latitude).

```{r bird_mod1, echo=TRUE,  fig.width=4, fig.height=4, message=F, warning=F, cache=T}
library(mgcv)
library(ggplot2)
library(tidyr)
library(viridis) #for color plotting

bird_move = read.csv("../data/bird_move.csv")

bird_mod1 = gam(count ~ te(week,latitude, bs= c("cc", "tp"), k=c(10,10)), 
                data= bird_move, method="REML", family= poisson)

plot(bird_mod1, page=1, scheme=2,rug = F)

```


The default plot for this GAM illustrates the average (log) abundance of all bird species at each latitude for each week, with yellow colours indicating more individuals and red colours fewer. This graph implies that these birds are starting at low latitudes in the winter then migrating to high latitudes from the 10th to 20th week, staying there for 15-20 weeks, then migrating back. However, the plot also indicates a large amount of uncertainty in the timing of migration. The source of this variability is apparent when the migration timing of each species is plotted in conjunction with the model fit:


```{r bird_mod1_ggplot, echo=TRUE,  fig.width=8, fig.height=3, message=F, warning=F, cache=T}

bird_move$mod1 = predict(bird_mod1,type ="response")
#gets the fitted model values, at the response scale

bird_move_plot = gather(bird_move, key = model,value = value, count,mod1)
#combines observed and fitted estimates into a single column called "value"

ggplot(data=bird_move_plot, aes(x=week, y=latitude, fill = value,color=value))+
  geom_tile(size=1)+
  facet_grid(model~species)+
  scale_fill_viridis("individuals")+
  scale_color_viridis("individuals")+
  scale_x_continuous(expand=c(0,0),breaks = c(1,26,52))+
  scale_y_continuous(expand=c(0,0), breaks=c(0,30,60))
```


Here the top row denotes the observed counts of each species (with color indicating relative abundance in that location in that week), and the bottom indicates the model fit. All six species show relatively precise migration patterns, but they differ in the timing of when they leave their winter grounds and the time they spend at their summer grounds. Averaging over all of this variation results in a relatively imprecise (diffuse) average estimate of migration timing (bottom row). This model could potentially be improved by adding inter-group variation in migration timing. The rest of this section will focus on how to model this type of variation. 


##Global function plus group-specific functions with similar smoothness (Model 2)

**EJP: I'm debating: should we re-arrange the order these are presented in, so just show an `fs` smooth by itself before having both `fs` group-level smooths and a global smooth in the same model? **

The second type of model is a close analogue to a GLMM with varying slopes. This class of model assumes that all groups will have similar functional responses, but allows for inter-group variation in responses. This approach works by allowing each grouping level to have its own functional response, but penalizing functions that are too far from the average. 

There are two ways code these types of models in `mgcv`(we will refer to them as model 2a and 2b): 

a) by explicitly specifying one term for the global smooth (as in model 1 above) then adding a second smooth term specifying the group level smooth terms, using a penalty term that tends to draw these group-level smooths to zero. For one-dimensional smooths, `mgcv` provides an explicit basis type to do this, the factor smooth or "fs" basis (see `?smooth.construct.fs.smooth.spec` for detailed notes). This smoother creates a copy of each set of basis functions for each level of the grouping variable, but only estimates one set of smoothing parameters for all groups. The penalty is also set up so each component of its null space is given its own penalty (so that all components of the smooth are penalized towards zero)[^f4]. As there can be issues of co-linearity between the global smooth term and the group-specific terms (see section V for more details), it is generally necessary to use a smoother with a more restricted null space than the global smooth; for thin plate splines this can be done by setting m=2 for the global smooth and m=1 for the group smooth [cite Wieling paper here]. e.g.: `y~s(x,bs="tp",m=2)+s(x,fac,bs="fs",m=1,xt=list(bs="tp"))`. 

b) The second way of specifying this type of smoother is by using a tensor product of whatever basis you choose for the continuous terms and a Markov Random Field smoother for the factor, with all of the groups in the MRF smoother being fully connected to one another. There is no need to specify a separate term here for the global smooth and group-level smoothers. Instead, this method will directly penalize differences between smooths, simultaneously fitting both the global effect and group-level deviations. e.g.: `y~te(x,fac,bs=c("tp","mrf"),xt=list(penalty=fac_pen_mat))`. This requires a helper function to create the fully connected penalty matrix, which we provide in the supplemental code as `create_connected_pmat`. 



[^f4]: As part of the penalty construction, each group will also have its own intercept (part of the penalized null space), so there is no need to add a separate term for group specific intercepts as we did in model 1. 


This is how the two approaches would be used to model variability in $CO_2$ uptake in the CO2 dataset:

```{r co2_mod2ab, echo=TRUE,  fig.width=6, fig.height=3,message=F, warning=F, cache=T}
source("../code/functions.R")
CO2_penmat = create_connected_pmat(CO2$Plant_uo)

CO2_mod2a = gam(log(uptake) ~ s(log(conc),k=6,m=2, bs="tp")+
                  s(log(conc), Plant_uo, k =6,  bs="fs",m=1), 
                data= CO2,method="REML")

CO2_mod2b = gam(log(uptake) ~ te(log(conc),Plant_uo, k=c(6,12),m=2, 
                                 bs=c("tp","mrf"), xt= list(penalty = CO2_penmat)), 
                data= CO2,method="REML")

plot(CO2_mod2a,page=1, seWithMean = T)
```



The above plot shows the global function (left) and group-specific deviations from the global function (right) for `CO2_mod2a`. The plots of group specific smooths indicate that plants differ not only in average log-uptake (which would correspond to each plant having a straight line at different levels for the group-level smooth), but differ slightly in the shape of their functional responses. We did not include a call to the plot function for `CO2_mod2b` as there is no default plotting method for a tensor product of a mrf smooth and a continous smoother. However, as is visible below, both smoothers have very similar behaviour when predicting group-specific variation: 

```{r co2_mod2ab_ggplot, echo=TRUE,  fig.width=6, fig.height=3,message=F, warning=F, cache=T}
CO2_mod2a_pred = predict(CO2_mod2a,se.fit = T)
CO2$mod2a = CO2_mod2a_pred$fit
CO2$mod2a_se = CO2_mod2a_pred$se.fit

CO2_mod2b_pred = predict(CO2_mod2b,se.fit = T)
CO2$mod2b = CO2_mod2b_pred$fit
CO2$mod2b_se = CO2_mod2b_pred$se.fit

ggplot(data=CO2, aes(x=conc, y= uptake, group=Plant_uo))+
  facet_wrap(~Plant_uo)+
  geom_point()+
  geom_line(aes(y=exp(mod2a)))+
  geom_line(color="red",aes(y=exp(mod2b)))+
  geom_ribbon(aes(ymin=exp(mod2a-2*mod2a_se), 
                  ymax=exp(mod2a+2*mod2a_se)),alpha=0.25)+
  geom_ribbon(fill="red",aes(ymin=exp(mod2b-2*mod2b_se), 
                             ymax=exp(mod2b+2*mod2b_se)),alpha=0.25)
```

The model 2a fit is shown in black, and the model 2b fit is shown in red. As mentioned above, both models show essentially identical fits to the this data set. 


The "fs"-based approach mentioned above for model 2a does not work for two or higher-dimensional smooths. Instead, the group-specific term can be specified with a tensor product of the continuous smooths and a random effect for the grouping parameter. This term will again have a separate set of basis functions for each group, one penalty for the smooth term, and a second penalty drawing all basis functions toward zero[^f5]. e.g.: `y~te(x1,x2,bs="tp",m=2)+te(x1,x2, fac,bs=c("tp","tp","fs"),m=1)`. The structure for model 2b does not substantially change in more than one dimension; a two dimensional model would be specified:`y~te(x1, x2, fac, bs=c("tp","tp","mrf"), xt=list(penalty=fac_pen_mat))`. We illustrate the two approaches below on the bird migration data.

[^f5]: Note that this differs from the "fs" penalty, which assigned one penalty per null space term.

```{r bird_mod2ab, echo=TRUE,  fig.width=4, fig.height=4, message=F, warning=F, cache=T}

bird_pen = create_connected_pmat(bird_move$species)

bird_mod2a = gam(count ~ te(week,latitude, bs= c("cc", "tp"), 
                           k=c(10,10),m=c(2,2))+
                  te(week,latitude,species, bs= c("cc", "tp","re"), 
                     k=c(10,10,6),m = c(1,1,1)), 
                data= bird_move, method="REML", family= poisson)

bird_mod2b = gam(count ~ te(week,latitude,species, bs= c("cc", "tp","mrf"), 
                            k=c(10,10,6),m = c(2,2,2),
                            xt =list(penalty= bird_pen)), 
                data= bird_move, method="REML", family= poisson)

plot(bird_mod2a, page=1, scheme=2,rug = F, seWithMean = T)

```



```{r bird_mod2ab_ggplot, echo=TRUE,  fig.width=8, fig.height=3, message=F, warning=F, cache=T}
bird_move$mod2a = predict(bird_mod2a,type ="response")
bird_move$mod2b = predict(bird_mod2b,type ="response")

bird_move_plot2 = gather(bird_move, key = model,value = value, count,mod2a,mod2b)

ggplot(data=bird_move_plot2, aes(x=week, y=latitude, fill = value,color=value))+
  geom_tile(size=1)+
  facet_grid(model~species)+
  scale_fill_viridis("individuals")+
  scale_color_viridis("individuals")+
  scale_x_continuous(expand=c(0,0),breaks = c(1,26,52))+
  scale_y_continuous(expand=c(0,0), breaks=c(0,30,60))
```

The two forms of model 2 tend to have similar fits on the same data set. So why not just focus on one or the other? Approach  **a** is useful as it gives a direct estimate of the overall smooth, and it is more straight-forward to incorporate "fixed" effects, where the global term captures large-scale differences between large classes in the data (say between treated and untreated levels in an experiment), and the group-level term models residual among-group functional variance (see [cite Wieling paper here] for a demonstration of this). For instance, in the $CO_2$ uptake analysis above, we could have allowed for average uptake differences between treatments by adding a `by` term: `log(uptake)~s(log(conc), by= Treatment, k=6)+ s(log(conc), Plant_uo, bs="fs",k=6)`. We will discuss using the `by=` argument more in the discussion on model 3. Approach **b** does not directly estimate a global smooth, although it can be derived by averaging equivilent basis functions across groups **EJP: should we demonstrate how to do this in paper?**. However, it does require estimating fewer penalty terms, and the general approach can be used to model more complex structural relationships between groups; for instance, if groups are patches in a metapopulation, the fully connected penalty matrix used above could be replaced by a connectivity matrix to determine if interpatch connectivity predicts functional similiarity between patches. In the bird migration case above, we could have used an inverse phylogenetic covariance matrix as the penalty term, to test if closely related species are more similiarly related in migration patterns than distantly related ones. The two models also differ in their computational properties; we will discuss the computational differences between the two approaches more in section V.


## Global function plus group-specific functions with different smoothness (Model 3)

This model class is very similar to model 2; the only change is that we will allow each group-specific smooth to have its own penalty term. This increases the computational cost of the model (more penalties means more computer time in general), and means that the only information shared between groups is through the global smoothing term. It is useful, however, if different groups differ substantially in how variable they are. 


```{r mod3, echo=TRUE,  fig.width=5, fig.height=3,message=F, warning=F, cache=T}


CO2_mod3 = gam(log(uptake) ~ s(log(conc),k=6,m=2, bs="tp")+
                  s(log(conc),by= Plant_uo, k =6,  bs="ts",m=1)+
                 s(Plant_uo,bs="re",k=12), 
                data= CO2,method="REML")

par(mfrow=c(2,3),mar =c(4, 4,1, 1))
plot(CO2_mod3,scale=0,select=14,ylab = "Intercepts",main=NA)
plot(CO2_mod3,scale=0,select=1, ylab = "global smooth",seWithMean = T)
plot(CO2_mod3,scale=0,select=2, ylab = "Plant Qn1",seWithMean = T)
plot(CO2_mod3,scale=0,select=5, ylab = "Plant Qc1",seWithMean = T)
plot(CO2_mod3,scale=0,select=9, ylab = "Plant Mn2",seWithMean = T)
plot(CO2_mod3,scale=0,select=12,ylab = "Plant Mc3",seWithMean = T)

bird_mod3 = gam(count ~ te(week,latitude, bs= c("cc", "tp"), 
                           k=c(10,10),m=c(2,2)) +
                  te(week,latitude, bs= c("cc", "tp"), 
                           k=c(10,10),m=c(1,1),by= species), 
                data= bird_move, method="REML", family= poisson)
```

```{r mod4, echo=TRUE,  fig.width=6, fig.height=3,message=F, warning=F, cache=T}


CO2_mod4 = gam(log(uptake) ~ s(log(conc), Plant_uo, k =6,  bs="fs",m=2), 
                data= CO2,method="REML")

bird_mod4 = gam(count ~ te(week,latitude,species, bs= c("cc", "tp","re"), 
                     k=c(10,10,6),m = 2), 
                data= bird_move, method="REML", family= poisson)

```


```{r mod5, echo=TRUE,  fig.width=6, fig.height=3,message=F, warning=F, cache=T}


CO2_mod5 = gam(log(uptake) ~ s(log(conc),by= Plant_uo, k =6,  bs="tp",m=2)+
                 s(Plant_uo,bs="re",k=12), data= CO2,method="REML")

bird_mod5 = gam(count ~ te(week,latitude,by=species, bs= c("cc", "tp"), 
                           k=c(10,10),m = 2), 
                data= bird_move, method="REML", family= poisson)

```